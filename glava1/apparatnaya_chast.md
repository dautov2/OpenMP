# Аппаратная часть


#### Параллелизм на уровне инструкций 

Программа состоит из множества инструкций к микропроцессору. Микропроцессор способен изменить порядок их выполнения, выделить среди инструкций группы, которые можно исполнять параллельно. При этом, результат вычислений не изменится. Так же микропроцессор способен предсказывать следующие инструкций. Ниже мы рассмотрим почему это бывает существенно. 

Данный уровень параллелизма эффективен в случае если вы хотите выжать максимум из своего железа. Однако, код после этого становится не переносимым.  

#### Иерархия памяти 
В большинстве современных ПК рассматривается следующая иерархия памяти:

* **Регистры** процессора, организованные в регистровый файл — наиболее быстрый доступ (порядка 1 такта), но размером лишь в несколько сотен или, редко, тысяч байт.

* **Кэш процессора 1го уровня (L1)** — время доступа порядка нескольких тактов, размером в десятки килобайт

* ** Кэш процессора 2го уровня (L2)** — большее время доступа (от 2 до 10 раз медленнее L1), около полумегабайта или более

* ** Кэш процессора 3го уровня (L3)** — время доступа около сотни тактов, размером в несколько мегабайт (в массовых процессорах используется недавно)

* **ОЗУ системы **— время доступа от сотен до, возможно, тысячи тактов, но огромные размеры в несколько гигабайт, вплоть до сотен. Время доступа к ОЗУ может варьироваться для разных его частей в случае комплексов класса NUMA (с неоднородным доступом в память)

* **Дисковое хранилище** — многие миллионы тактов, если данные не были закэшированны или забуферизованны заранее, размеры до нескольких терабайт

| Операция | Такты | Время мс | Отношение |
| -- | -- | -- | -- |
|Один такт процессора с частотой 3 ГГц| 1 | | |
| Обращение в кэш перого уровня L1  | 0.5 |   |  |
| Неверно предсказанный переход     | 5   |   | |
| Обращение в кэш второго уровня L2 | 7  |   | 14x L1 |
| Захват мьютекса                   | 100 |   |  |
| Обращение в оперативную память | 100 |   |20x L2 , 200x L1|
| Snappy сжатие 1 Кбайта данных  | 3000 |   | |
| Передача 2 Кбайт через 1 Гбит|10000|0.01||
| Прочитать произвольные 4 Кбайт данных с SSD|150000 |0.15 ||
| Прочитать последовательно 1 Мбайт данных из памяти |250000|0.25||
| Прочитать последовательно 1 Мбайт данных  с SSD |1000000|1|4x память|
| Прочитать последовательно 1 Мбайт данных из сети|10000000|10||
| Прочитать последовательно 1 Мбайт данных с диска|20000000|20|80x память, 40х SSD|

#### Мультипроцессорные системы 
Использование пары или большего количества физических процессоров в одной компьютерной системе. Термин также относится к способности системы поддержать больше чем один процессор и/или способность распределить задачи между ними. Существует много вариантов данного понятия, и определение многопроцессорности может меняться в зависимости от контекста, главным образом в зависимости от того, как определены процессоры (много ядер в одном кристалле, множество чипов в одном корпусе, множество корпусов в одном системном модуле, и т. д.).

#### Присоединённые устройства

##### Архитектура NVIDIA CUDA
![](tesla.jpg)

Сама парадигма приложений использующих графические ускорители появилась в 2003 году. В основсном этим занимались энтузиасты. Однако, компания NVidia рассмотрела в этом потенциал. Потенциал так же увидели ряд нефтяных компаний, перед которыми стояли проблемы обработки больших объемов данных и масштабных расчетов. Эти компании так же могли инвестировать средства в разработку.

После создания первых карт для вычислений, встал вопрос создания удобного языка программирования для GPU. Добавив расширение для языка программирования С и С++. Программирование для графических процессоров вышло на новый уровень. Резко возросло количество научных публикаций. Применение GPU стало распространятся на многие сферы. Именно момент внесения расширения для языков программирования, можно считать рождением архитектуры CUDA для GPU. 


![](cpu-and-gpu.jpg)

Компания NVidia так же развивает свои библиотеки для удобства разработки под эти устройства, в каждую новая редакцию библиотек вносятся новые алгоритмы и более оптимальные решения старых. Например, библиотека cuBLAS. cuBLAS это реализация библиотеки BLAS(Basic Linear Algebra Subprograms- Базовые Подпрограммы Линейной Алгебры) стандарт де-факто интерфейса программирования приложений для создания библиотек, выполняющих основные операции линейной алгебры, такие как умножение векторов и матриц.

Кроме того, центральные процессоры используют SIMD (одна инструкция выполняется над многочисленными данными) блоки для векторных вычислений, а видеочипы применяют SIMT (одна инструкция и несколько потоков) для скалярной обработки потоков. SIMT не требует, чтобы разработчик преобразовывал данные в векторы, и допускает произвольные ветвления в потоках.

Так же стоит отметить при использовании GPU разработчику доступно несколько видов памяти: регистры, локальная, глобальная, разделяемая, константная и текстурная память. Каждая из этих типов памяти имеет определённое назначение, которое обуславливается её техническими параметрами (скорость работы, уровень доступа на чтение и запись).

Ниже приведена архитектура устройства:
![](GeForce-8800-GTX-2.png)



##### Архитектура Intel MIC (Many Integrated Core Architecture)

![](Xeon_Phi_PCIe_Card_M.jpg)

В основе архитектуры Intel MIC лежит классическая архитектура x86, на ускорителе исполняется ОС Linux. Для программирования MIC предполагается использовать OpenMP, OpenCL, Intel Cilk Plus, специализированные компиляторы Intel Fortran, Intel C++. Также предоставляются математические библиотеки.

От Larrabee унаследована набор команд x86, 512-битные векторные АЛУ (до 16 операций над float или до 8 операций над double в инструкции), когерентный L2 кеш размером 512 КБ на ядро, и сверхширокая кольцевая шина для связи ядер и контроллера памяти.

Ниже приведена архитектура устройства:
![](Many-Core2.jpg)